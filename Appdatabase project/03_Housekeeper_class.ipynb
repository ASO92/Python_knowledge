{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housekeeper module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path \n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "class data_housekeeper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_dir(myDir):\n",
    "        try:\n",
    "            if not path.exists(myDir):\n",
    "                print('Creating dir: ', myDir)\n",
    "                os.mkdir(myDir)\n",
    "        except AccessDeniedError as err:\n",
    "            print('No dir created: ', err)\n",
    "\n",
    "    @staticmethod\n",
    "    def delete_dir(myDir):\n",
    "        try:\n",
    "            if path.exists(myDir):\n",
    "                print('Deleting dir: ', myDir)\n",
    "                os.rmdir(myDir)\n",
    "            else:\n",
    "                print('Inexistent folder')\n",
    "        except AccessDeniedError as err:\n",
    "            print('No dir deleted: ', err)\n",
    "\n",
    "    @staticmethod\n",
    "    def delete_non_empty_dir(myDir):\n",
    "        try:\n",
    "            if path.exists(myDir):\n",
    "                print('Deleting dir: ', myDir)\n",
    "                shutil.rmtree(myDir)\n",
    "        except:\n",
    "            print('No dir deleted: ')        \n",
    "\n",
    "    @staticmethod\n",
    "    def create_nested_dir_path(dir_list):\n",
    "        nested_path = '/' + '/'.join(dir_list)\n",
    "        return nested_path\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def create_file_path_in_nested_dir(dir_list, file_name):\n",
    "        nested_dir_path_ = data_housekeeper.create_nested_dir_path(dir_list)\n",
    "        #print('nested_dir_path: ', nested_dir_path_)\n",
    "        file_path_in_nested_dir_ = nested_dir_path_ + '/' + file_name\n",
    "        return file_path_in_nested_dir_\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def create_nested_dir(dir_path):\n",
    "        try:\n",
    "            myPath = ''\n",
    "            for directory in dir_path:\n",
    "                myPath += './' + directory\n",
    "                data_housekeeper.create_dir(myPath)\n",
    "            #print(myPath)\n",
    "        except:\n",
    "            print('No nested dir created')\n",
    "            #print(myPath)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_nested_dir_in_parent_dir(dir_path , n):\n",
    "        try:\n",
    "            origin_wd = os.getcwd()\n",
    "            for n in range(n):\n",
    "                path_parent = os.path.dirname(os.getcwd())\n",
    "                os.chdir(path_parent)\n",
    "            root_dir = os.getcwd()\n",
    "            print('Root dir: ', root_dir)\n",
    "            data_housekeeper.create_nested_dir(dir_path)\n",
    "            os.chdir(origin_wd)\n",
    "            return root_dir\n",
    "        except:\n",
    "            os.chdir(origin_wd)\n",
    "            print('Error: No directory created. Posible causes: \\nWrong type imput arguments \\nUnable to access to nested dir')\n",
    "            return os.getcwds()\n",
    "                \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def list_dict_to_json(dir_list,upper_stages,file_name, dictionary_list): \n",
    "        parent_dir_path = data_housekeeper.create_nested_dir_in_parent_dir(dir_list,upper_stages)\n",
    "        print('parent_dir_path: ', parent_dir_path)\n",
    "        print('dir_list: ', dir_list)\n",
    "        file_path = parent_dir_path + data_housekeeper.create_file_path_in_nested_dir(dir_list, file_name)\n",
    "        print('file path: ', file_path)\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(dictionary_list, json_file, indent=4)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_json_to_list(dir_list, file_name): #FIX cambiar el nombre a json_to_list \n",
    "        relative_file_path_ = '.' + data_housekeeper.create_file_path_in_nested_dir(dir_list, file_name)\n",
    "        print(relative_file_path_)\n",
    "        with open(relative_file_path_) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def list_to_csv(dir_list, upper_stages, file_name, data):\n",
    "        relative_file_path_ = '.' + data_housekeeper.create_file_path_in_nested_dir(dir_list, file_name)\n",
    "        print(relative_file_path_)\n",
    "        with open(relative_file_path_, 'w', newline='') as file:\n",
    "            write = csv.writer(file)\n",
    "            write.writerows(data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def df_to_csv(dir_list, upper_stages, file_name, data):\n",
    "        relative_file_path_ = '.' + data_housekeeper.create_file_path_in_nested_dir(dir_list, file_name) + '.csv'\n",
    "        print(relative_file_path_)\n",
    "        data.to_csv(relative_file_path_, index = False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def csv_to_df(dir_list, file_name):\n",
    "        relative_file_path_ = '.' + data_housekeeper.create_file_path_in_nested_dir(dir_list, file_name) + '.csv'\n",
    "        print(relative_file_path_)\n",
    "        return pd.read_csv(relative_file_path_)\n",
    "            \n",
    "        \n",
    "def instance_class():\n",
    "    myHousekeeper = data_housekeeper()\n",
    "    return myHousekeeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/Tickers/Dummy1/ANA.MC.TT.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./Data/Tickers/Dummy1/ANA.MC.TT.csv does not exist: './Data/Tickers/Dummy1/ANA.MC.TT.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0197fffff7b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_housekeeper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mDH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tickers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dummy1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ANA.MC.TT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-71bc071650ea>\u001b[0m in \u001b[0;36mcsv_to_df\u001b[1;34m(dir_list, file_name)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mrelative_file_path_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_housekeeper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_file_path_in_nested_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelative_file_path_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelative_file_path_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Trading_tool_reqs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Trading_tool_reqs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Trading_tool_reqs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Trading_tool_reqs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Trading_tool_reqs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ./Data/Tickers/Dummy1/ANA.MC.TT.csv does not exist: './Data/Tickers/Dummy1/ANA.MC.TT.csv'"
     ]
    }
   ],
   "source": [
    "DH = data_housekeeper()\n",
    "DH.csv_to_df(['Data', 'Tickers', 'Dummy1'],'ANA.MC.TT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "data_csv = yf.download('ACX.MC')\n",
    "data_csv.insert(loc=0, column='Date', value=pd.to_datetime(data_csv.index, errors='coerce'))\n",
    "data_csv['Date'] = [time.date() for time in data_csv['Date']]\n",
    "data_csv.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config parameters to save\n",
    "dir_list = ['Data', 'Tickers', 'Dummy1']\n",
    "upper_stages = 0\n",
    "file_name = 'data_df.csv'\n",
    "data = data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(dir_list, upper_stages, file_name, data):\n",
    "        relative_file_path_ = '.' + data_housekeeper.create_file_path_in_nested_dir(dir_list, file_name)\n",
    "        print(relative_file_path_)\n",
    "        #Dataframe\n",
    "        data.to_csv(relative_file_path_ , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/Tickers/Dummy1/data_df.csv\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(dir_list, upper_stages, file_name, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprender a subir de directorio en la ruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nums =  [[10,20,30],\n",
    "        [40,50,60],\n",
    "        [70,80,90]]\n",
    "mypath3 = 'data_file/number.csv'\n",
    "file = open(mypath3, 'w')\n",
    "\n",
    "with file:\n",
    "    write = csv.writer(file)\n",
    "    write.writerows(nums) # Rather than iterating over the individual rows, and then writing them to the file using the write.row function, we simply call the write.rows funtcion with an S in order\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums =  [[10,20,30],\n",
    "        [40,50,60],\n",
    "        [70,80,90]]\n",
    "\n",
    "def list_to_csv(dir_list, upper_stages, file_name, data):\n",
    "        relative_file_path_ = '.' + data_housekeeper.create_file_path_in_nested_dir(dir_list, file_name)\n",
    "        print(relative_file_path_)\n",
    "        with open(relative_file_path_, 'w', newline='') as file:\n",
    "            write = csv.writer(file)\n",
    "            write.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housekeeper.list_to_csv(dir_list, upper_stages, file_name, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config parameters to save\n",
    "dir_list = ['Data', 'Tickers']\n",
    "upper_stages = 0\n",
    "file_name = 'tickers_test.json'\n",
    "dictionary_list = [{'key11':'value11', 'key12':'value12','key13':{'subkey131':'subvalue131'} }, {'key21':'value21', 'key22':'value22','key23':{'subkey231':'subvalue231'}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housekeeper.list_dict_to_json(dir_list,upper_stages,file_name,dictionary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_housekeeper.load_json_to_list(dir_list, file_name)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPath =data_housekeeper.create_nested_path(['Data', 'Tickers'])\n",
    "myPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housekeeper.create_nested_dir(['Data', 'Tickers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_dir(myDir):\n",
    "        try:\n",
    "            if path.exists(myDir):\n",
    "                print('Deleting dir: ', myDir)\n",
    "                os.rmdir(myDir)\n",
    "        except AccessDeniedError as err:\n",
    "            print('No dir deleted: ', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housekeeper.delete_dir('./Data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_non_empty_dir(myDir):\n",
    "        try:\n",
    "            if path.exists(myDir):\n",
    "                print('Deleting dir: ', myDir)\n",
    "                shutil.rmtree(myDir)\n",
    "        except AccessDeniedError as err:\n",
    "            print('No dir deleted: ', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housekeeper.delete_non_empty_dir('./Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housekeeper.create_dir(dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_dir_path = ['Data', 'Tickers']\n",
    "file_name = 'hola.txt'\n",
    "file_path = './' + '/'.join(tickers_dir_path) +'/'+file_name\n",
    "#file_path = './' + '/'.join(tickers_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os import path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "script_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parent = os.path.dirname(script_dir)\n",
    "path_parent\n",
    "os.chdir(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(script_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "for n in range(n):\n",
    "    origin_wd = os.getcwd()\n",
    "    print(n)\n",
    "    path_parent = os.path.dirname(os.getcwd())\n",
    "    os.chdir(path_parent)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os import path \n",
    "import json\n",
    "\n",
    "def create_dir(myDir):\n",
    "    try:\n",
    "        if not path.exists(myDir):\n",
    "            print('Creating dir: ', myDir)\n",
    "            os.mkdir(myDir)\n",
    "    except AccessDeniedError as err:\n",
    "        print('No dir created: ', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nested_dir(dir_path):\n",
    "    try:\n",
    "        myPath = ''\n",
    "        for directory in dir_path:\n",
    "            myPath += './' + directory\n",
    "            create_dir(myPath)\n",
    "        #print(myPath)\n",
    "    except AccessDeniedError as err:\n",
    "        print('No nested dir created: ', err)\n",
    "        #print(myPath)\n",
    "        \n",
    "        \n",
    "#file_path = './' + '/'.join(dir_path) +'/'+ file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nested_dir_in_parent_dir(dir_path , n):\n",
    "    try:\n",
    "        origin_wd = os.getcwd()\n",
    "        for n in range(n):\n",
    "            path_parent = os.path.dirname(os.getcwd())\n",
    "            os.chdir(path_parent)\n",
    "        root_dir = os.getcwd()\n",
    "        print('Root dir: ', root_dir)\n",
    "        create_nested_dir(dir_path)\n",
    "        os.chdir(origin_wd)\n",
    "        return root_dir\n",
    "    except:\n",
    "        os.chdir(origin_wd)\n",
    "        print('Error: No directory created. Posible causes: \\nWrong type imput arguments \\nUnable to access to nested dir')\n",
    "        return os.getcwds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dict_to_json(dir_list,upper_stages,file_name, dictionary_list):\n",
    "    dir_path = create_nested_dir_in_parent_dir(dir_list,upper_stages)\n",
    "    print('dir_path: ', dir_path)\n",
    "    print('dir_list: ', dir_list)\n",
    "    nested_path = '/' + '/'.join(dir_list) +'/'\n",
    "    print('nested_path: ', nested_path)\n",
    "    file_path = dir_path + nested_path+ file_name\n",
    "    print('file path: ', file_path)\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        for ticker in dictionary_list:\n",
    "            #json.dump(ticker, json_file, separators=(\":\", \",\\n\"))\n",
    "            json.dump(ticker, json_file, separators=(\":\", \",\"))\n",
    "            json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = ['Data', 'Tickers']\n",
    "#dir_list = True\n",
    "upper_stages = 0\n",
    "file_name = 'tickers.txt'\n",
    "dictionary_list = ['hola', 'mundo']\n",
    "list_dict_to_json(dir_list, upper_stages, file_name, dictionary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_housekeeper.list_dict_to_json(tickers_dir_path,1,'tickers.txt',list_to_write)\n",
    "#def list_dict_to_json(dir_list,upper_stages,file_name, dictionary_list):\n",
    "dir_list = ['Data', 'Tickers']\n",
    "upper_stages = 1\n",
    "file_name = 'tickers.txt'\n",
    "dictionary_list = ['hola', 'mundo']\n",
    "\n",
    "dir_path = create_nested_dir_in_parent_dir(dir_list,upper_stages)\n",
    "print('dir_path: ', dir_path)\n",
    "print('dir_list: ', dir_list)\n",
    "nested_path = '/' + '/'.join(dir_list) +'/'\n",
    "print('nested_path: ', nested_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = './' + '/'.join(dir_path) +'/'+ file_name\n",
    "file_path = dir_path + nested_path+ file_name\n",
    "print('file path: ', file_path)\n",
    "#with open(file_path, 'w') as json_file:\n",
    "#'./Data/Tickers/tickers.txt'\n",
    "#with open('.\\Data\\Tickers\\tickers.txt', 'w') as json_file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'w') as json_file:\n",
    "    for ticker in dictionary_list:\n",
    "        #json.dump(ticker, json_file, separators=(\":\", \",\\n\"))\n",
    "        json.dump(ticker, json_file, separators=(\":\", \",\"))\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = ['Data', 'Tickers']\n",
    "upper_stages = 2\n",
    "file_name = 'tickers.txt'\n",
    "dictionary_list = ['hola', 'mundo']\n",
    "\n",
    "dir_path = create_nested_dir_in_parent_dir(dir_list,upper_stages)\n",
    "print('dir_path: ', dir_path)\n",
    "print('dir_list: ', dir_list)\n",
    "nested_path = '/' + '/'.join(dir_list) +'/'\n",
    "print('nested_path: ', nested_path)\n",
    "file_path = dir_path + nested_path+ file_name\n",
    "print('file path: ', file_path)\n",
    "with open(file_path, 'w') as json_file:\n",
    "    for ticker in dictionary_list:\n",
    "        #json.dump(ticker, json_file, separators=(\":\", \",\\n\"))\n",
    "        json.dump(ticker, json_file, separators=(\":\", \",\"))\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =1\n",
    "create_nested_dir_in_parent_dir(['Data', 'Tickers'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_dir(['Data', 'Tickers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parent = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_parent) #Change directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This takes the filename of your script, converts it to an absolute path, then extracts the directory of that path, then changes into that directory.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abspath = os.path.abspath(__file__)\n",
    "dname = os.path.dirname(abspath)\n",
    "os.chdir(dname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Going to directory where the python packages are installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "os.chdir(os.path.dirname(sys.argv[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abspath = os.path.abspath(sys.argv[0])\n",
    "abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = os.path.dirname(abspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
